{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Road Accident Severity Classification (Template)\n",
        "\n",
        "**Research question:** Can machine learning models classify countries based on the level of road accident severity using existing road accident and fatality statistics along with demographic and traffic-related indicators?\n",
        "\n",
        "Use this template to complete the classification task. Replace TODOs with your own work, results, and interpretations based on the assignment instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running in Colab, install the essentials (uncomment if needed)\n",
        "# !pip -q install pandas numpy scikit-learn matplotlib seaborn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the path if needed\n",
        "data_path = '/content/road_accident_dataset.csv'  # Colab example\n",
        "# data_path = '/Users/aryadevrijal/Downloads/road_accident_dataset.csv'  # local example\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Understand the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.describe(include='all').T.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Target and Features\n",
        "**TODO:** Identify the target column for *severity class* (e.g., Low/Medium/High).\n",
        "If you need to create the target (e.g., binning a fatality rate), do it here and justify the thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example placeholder\n",
        "# target_col = 'Severity_Class'\n",
        "# df[target_col].value_counts()\n",
        "\n",
        "# TODO: replace with the correct target column name\n",
        "target_col = 'Severity_Class'\n",
        "\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Preprocessing\n",
        "Handle missing values and scale numeric features. If you have categorical features, decide how to encode them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = X.select_dtypes(include=['int64','float64']).columns\n",
        "categorical_cols = X.select_dtypes(include=['object','category']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "    ,('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Simple one-hot for categorical columns (if any)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
        "    ,('onehot', __import__('sklearn').preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Baseline Model (Logistic Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_reg = Pipeline(steps=[\n",
        "    ('preprocess', preprocess),\n",
        "    ('model', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('\nClassification Report:\n', classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Alternative Model (Random Forest)\n",
        "Use a second model to compare performance. Keep it simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = Pipeline(steps=[\n",
        "    ('preprocess', preprocess),\n",
        "    ('model', RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
        "print('\nClassification Report:\n', classification_report(y_test, y_pred_rf))\n",
        "\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('Confusion Matrix - Random Forest')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Feature Importance (Optional, if required)\n",
        "Use this only if the assignment requires it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: show top features from Random Forest\n",
        "# This requires getting feature names after preprocessing\n",
        "# If you have categorical variables, one-hot expansion increases feature count.\n",
        "\n",
        "# Uncomment and adapt if required\n",
        "# ohe = rf.named_steps['preprocess'].named_transformers_['cat'].named_steps['onehot']\n",
        "# cat_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
        "# feature_names = np.concatenate([numeric_cols, cat_feature_names])\n",
        "# importances = rf.named_steps['model'].feature_importances_\n",
        "# imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "# imp_df.sort_values('importance', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Conclusion\n",
        "Write a short conclusion answering the research question and summarizing results.\n",
        "\n",
        "**TODO:** Add your conclusion here."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
